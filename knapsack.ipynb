{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akRwxDQwP8aA"
      },
      "outputs": [],
      "source": [import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf

from keras.datasets import mnist
from tensorflow.keras.optimizers.legacy import SGD, Adam
from tensorflow.keras.utils import to_categorical
from keras.backend import image_data_format
from keras.applications.mobilenet import MobileNet
from keras.callbacks import ModelCheckpoint
from keras.models import Sequential
from tensorflow import keras
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dropout
from keras.layers import Dense
from keras.models import Sequential
import random
import time
import matplotlib.pyplot as plt
import numpy as np
import copy

import csv
import random
import time

# client config
NUMOFCLIENTS = 10 # number of client(as particles)
EPOCHS = 30 # number of total iteration
CLIENT_EPOCHS = 1 # number of each client's iteration
BATCH_SIZE = 5 # Size of batches to train on
ACC = 0.3 # 0.4
LOCAL_ACC = 0.7 # 0.6
GLOBAL_ACC = 1.4 # 1.0

DROP_RATE = 0 # 0 ~ 1.0 float value


# model config
LOSS = 'categorical_crossentropy' # Loss function
NUMOFCLASSES = 10 # Number of classes
lr = 0.0025
OPTIMIZER = SGD(lr=lr, momentum=0.9, decay=lr/(EPOCHS*CLIENT_EPOCHS), nesterov=False) # lr = 0.015, 67 ~ 69%



def load_dataset():
    """
    This function loads the dataset provided by Keras and pre-processes it in a form that is good to use for learning.

    Return:
        (X_train, Y_train), (X_test, Y_test)
    """

    # Code for experimenting with MNIST datasets.
    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)

    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train = X_train / 255.0
    X_test = X_test / 255.0

    Y_train = to_categorical(Y_train)
    Y_test = to_categorical(Y_test)

    return (X_train, Y_train), (X_test, Y_test)

    {
      "cell_type": "code",
      "source": [
        "# create CNN Model\n",
        "\n",
        "class Model():\n",
        "\n",
        "    def __init__(self, loss, optimizer, classes=10):\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.num_classes = classes\n",
        "\n",
        "    @staticmethod\n",
        "    def build(input_shape, classes, final_activation, drop_rate=0):\n",
        "        model = Sequential()\n",
        "\n",
        "        # 1\n",
        "        model.add(Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            input_shape=input_shape,\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(MaxPooling2D(\n",
        "            pool_size=(2,2),\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "        # 2\n",
        "        model.add(Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(MaxPooling2D(\n",
        "            pool_size=(2,2),\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "        # 3\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(\n",
        "            units=512,\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "        # 4\n",
        "        model.add(Dense(\n",
        "            units=classes,\n",
        "            activation=final_activation\n",
        "        ))\n",
        "\n",
        "        model.compile(\n",
        "            loss='categorical_crossentropy',  # Using categorical_crossentropy since the final layer uses softmax\n",
        "            optimizer=Adam(lr=0.0025),  # Adjust the learning rate if needed\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "loY57-H6QJbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Client selection algorithm using knapsack model\n",
        "\n",
        "def knapsack_with_features(clients, capacity):\n",
        "    n = len(clients)\n",
        "    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(capacity + 1):\n",
        "            if clients[i - 1]['Energy'] <= w:\n",
        "                dp[i][w] = max(dp[i - 1][w], clients[i - 1]['Reliability'] + dp[i - 1][w - clients[i - 1]['Energy']])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "\n",
        "    selected_clients = []\n",
        "    i, j = n, capacity\n",
        "    while i > 0 and j > 0:\n",
        "        if dp[i][j] != dp[i - 1][j]:\n",
        "            selected_clients.append(i - 1)\n",
        "            j -= clients[i - 1]['Energy']\n",
        "        i -= 1\n",
        "\n",
        "    selected_client_features = [clients[idx] for idx in selected_clients]\n",
        "\n",
        "    return selected_clients, selected_client_features\n",
        "\n",
        "# Client features:\n",
        "clients = [\n",
        "    {\"Di\": 6000, \"Loss\": 0.3372, \"Delay\": 1.421, \"Energy\": 58, \"Reliability\": 0.1210938634, \"Fairness\": 0.66},\n",
        "    {\"Di\": 6000, \"Loss\": 0.6755, \"Delay\": 2, \"Energy\": 64, \"Reliability\": 0.04978706837, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.5286, \"Delay\": 2.16, \"Energy\": 47, \"Reliability\": 0.2493522088, \"Fairness\": 0.63},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4091, \"Delay\": 1.27, \"Energy\": 38, \"Reliability\": 1, \"Fairness\": 0.6},\n",
        "    {\"Di\": 6000, \"Loss\": 0.3258, \"Delay\": 1.17, \"Energy\": 42, \"Reliability\": 1, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4178, \"Delay\": 1.753, \"Energy\": 65, \"Reliability\": 0.1806214331, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.13236, \"Delay\": 1.8, \"Energy\": 36, \"Reliability\": 0.03567399335, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.2377, \"Delay\": 2.142, \"Energy\": 13, \"Reliability\": 1, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.323, \"Delay\": 2.52, \"Energy\": 16,\"Reliability\": 0.02811565975, \"Fairness\": 0.9333333333},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4094, \"Delay\": 1.8, \"Energy\": 96, \"Reliability\": 0.1888756028, \"Fairness\": 0.9333333333}\n",
        "]\n",
        "capacity = 200\n",
        "\n",
        "selected_clients, selected_client_features = knapsack_with_features(clients, capacity)\n",
        "print(\"Selected clients:\", selected_clients)\n",
        "print(\"Selected client features:\", selected_client_features)"
      ],
      "metadata": {
        "id": "Og5zCJ-CQXm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Create and compile the client model\n",
        "def create_client_model():\n",
        "    model = Model.build(input_shape=(28, 28, 1), classes=NUMOFCLASSES, final_activation='softmax', drop_rate=DROP_RATE)\n",
        "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Select clients based on knapsack scores\n",
        "def select_clients(knapsack_scores, num_clients):\n",
        "\n",
        "    selected_clients = np.argsort(knapsack_scores)[-num_clients:]\n",
        "    return selected_clients\n",
        "\n",
        "# Perform federated learning with client selection\n",
        "def federated_learning_with_selection(clients, capacity, num_clients, num_epochs, client_epochs, batch_size):\n",
        "    # Load dataset\n",
        "    (X_train, Y_train), (X_test, Y_test) = load_dataset()\n",
        "\n",
        "    # Initialize global model\n",
        "    global_model = create_client_model()\n",
        "\n",
        "    # Initialize knapsack scores for each client\n",
        "    knapsack_scores = [random.uniform(0, 1) for _ in range(len(clients))]\n",
        "\n",
        "    # Federated learning loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nGlobal Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        start_global_time = time.time()\n",
        "\n",
        "        # Select clients using knapsack algorithm\n",
        "        selected_clients_indices, _ = knapsack_with_features(clients, capacity)\n",
        "        selected_clients = [clients[i] for i in selected_clients_indices]\n",
        "\n",
        "        for client in selected_clients:\n",
        "            print(f\"\\nClient {clients.index(client) + 1}/{len(clients)}\")\n",
        "            # Create a local model\n",
        "            local_model = create_client_model()\n",
        "\n",
        "            # Train the local model\n",
        "            start_local_time = time.time()\n",
        "            local_model.fit(X_train, Y_train, epochs=client_epochs, batch_size=batch_size, verbose=0)\n",
        "            end_local_time = time.time()\n",
        "\n",
        "            # Evaluate local model on client's data\n",
        "            _, local_accuracy = local_model.evaluate(X_test, Y_test, verbose=0)\n",
        "            local_loss = 1 - local_accuracy\n",
        "\n",
        "            # Update knapsack score for the client\n",
        "            knapsack_scores[clients.index(client)] = local_loss\n",
        "\n",
        "            # Print results for each iteration\n",
        "            print(f\"Iteration {client_epochs}, Time: {end_local_time - start_local_time:.2f}s, Accuracy: {local_accuracy * 100:.2f}%, Loss: {local_loss:.4f}\")\n",
        "\n",
        "            # Aggregate models from selected clients into the global model (in this example, simply update the global model)\n",
        "            global_model.set_weights(local_model.get_weights())\n",
        "\n",
        "        end_global_time = time.time()\n",
        "        global_accuracy = global_model.evaluate(X_test, Y_test)[1]\n",
        "        global_loss = 1 - global_accuracy\n",
        "        print(f\"\\nGlobal Epoch Time: {end_global_time - start_global_time:.2f}s, Global Accuracy: {global_accuracy * 100:.2f}%, Global Loss: {global_loss:.4f}\")\n",
        "\n",
        "    # Evaluate the final global model\n",
        "    _, final_accuracy = global_model.evaluate(X_test, Y_test)\n",
        "    print(f\"\\nFinal Global Model Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Example:\n",
        "clients = [\n",
        "    {\"Di\": 6000, \"Loss\": 0.3372, \"Delay\": 1.421, \"Energy\": 58, \"Reliability\": 0.1210938634, \"Fairness\": 0.66},\n",
        "    {\"Di\": 6000, \"Loss\": 0.6755, \"Delay\": 2, \"Energy\": 64, \"Reliability\": 0.04978706837, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.5286, \"Delay\": 2.16, \"Energy\": 47, \"Reliability\": 0.2493522088, \"Fairness\": 0.63},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4091, \"Delay\": 1.27, \"Energy\": 38, \"Reliability\": 1, \"Fairness\": 0.6},\n",
        "    {\"Di\": 6000, \"Loss\": 0.3258, \"Delay\": 1.17, \"Energy\": 42, \"Reliability\": 1, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4178, \"Delay\": 1.753, \"Energy\": 65, \"Reliability\": 0.1806214331, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.13236, \"Delay\": 1.8, \"Energy\": 36, \"Reliability\": 0.03567399335, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.2377, \"Delay\": 2.142, \"Energy\": 13, \"Reliability\": 1, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.323, \"Delay\": 2.52, \"Energy\": 16,\"Reliability\": 0.02811565975, \"Fairness\": 0.9333333333},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4094, \"Delay\": 1.8, \"Energy\": 96, \"Reliability\": 0.1888756028, \"Fairness\": 0.9333333333}\n",
        "]\n",
        "capacity = 200\n",
        "NUMOFCLASSES = 10\n",
        "LOSS = 'categorical_crossentropy'\n",
        "OPTIMIZER = 'adam'\n",
        "DROP_RATE = 0.25\n",
        "EPOCHS = 30\n",
        "CLIENT_EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "federated_learning_with_selection(clients, capacity, NUMOFCLIENTS, EPOCHS, CLIENT_EPOCHS, BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "uZRI9czOctYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
