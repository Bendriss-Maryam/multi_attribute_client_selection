{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akRwxDQwP8aA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers.legacy import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.backend import image_data_format\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import time\n",
        "\n",
        "# client config\n",
        "NUMOFCLIENTS = 10 # number of client(as particles)\n",
        "EPOCHS = 30 # number of total iteration\n",
        "CLIENT_EPOCHS = 1 # number of each client's iteration\n",
        "BATCH_SIZE = 5 # Size of batches to train on\n",
        "ACC = 0.3 # 0.4\n",
        "LOCAL_ACC = 0.7 # 0.6\n",
        "GLOBAL_ACC = 1.4 # 1.0\n",
        "\n",
        "DROP_RATE = 0 # 0 ~ 1.0 float value\n",
        "\n",
        "\n",
        "# model config\n",
        "LOSS = 'categorical_crossentropy' # Loss function\n",
        "NUMOFCLASSES = 10 # Number of classes\n",
        "lr = 0.0025\n",
        "OPTIMIZER = SGD(lr=lr, momentum=0.9, decay=lr/(EPOCHS*CLIENT_EPOCHS), nesterov=False) # lr = 0.015, 67 ~ 69%\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    \"\"\"\n",
        "    This function loads the dataset provided by Keras and pre-processes it in a form that is good to use for learning.\n",
        "\n",
        "    Return:\n",
        "        (X_train, Y_train), (X_test, Y_test)\n",
        "    \"\"\"\n",
        "\n",
        "    # Code for experimenting with MNIST datasets.\n",
        "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "\n",
        "    Y_train = to_categorical(Y_train)\n",
        "    Y_test = to_categorical(Y_test)\n",
        "\n",
        "    return (X_train, Y_train), (X_test, Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create CNN Model\n",
        "\n",
        "class Model():\n",
        "\n",
        "    def __init__(self, loss, optimizer, classes=10):\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.num_classes = classes\n",
        "\n",
        "    @staticmethod\n",
        "    def build(input_shape, classes, final_activation, drop_rate=0):\n",
        "        model = Sequential()\n",
        "\n",
        "        # 1\n",
        "        model.add(Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            input_shape=input_shape,\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(MaxPooling2D(\n",
        "            pool_size=(2,2),\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "        # 2\n",
        "        model.add(Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5, 5),\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(MaxPooling2D(\n",
        "            pool_size=(2,2),\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "        # 3\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(\n",
        "            units=512,\n",
        "            activation='relu',\n",
        "            kernel_regularizer='l2',\n",
        "        ))\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "        # 4\n",
        "        model.add(Dense(\n",
        "            units=classes,\n",
        "            activation=final_activation\n",
        "        ))\n",
        "\n",
        "        model.compile(\n",
        "            loss='categorical_crossentropy',  # Using categorical_crossentropy since the final layer uses softmax\n",
        "            optimizer=Adam(lr=0.0025),  # Adjust the learning rate if needed\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "loY57-H6QJbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Client selection algorithm using knapsack model\n",
        "\n",
        "def knapsack_with_features(clients, capacity):\n",
        "    n = len(clients)\n",
        "    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(capacity + 1):\n",
        "            if clients[i - 1]['Energy'] <= w:\n",
        "                dp[i][w] = max(dp[i - 1][w], clients[i - 1]['Reliability'] + dp[i - 1][w - clients[i - 1]['Energy']])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "\n",
        "    selected_clients = []\n",
        "    i, j = n, capacity\n",
        "    while i > 0 and j > 0:\n",
        "        if dp[i][j] != dp[i - 1][j]:\n",
        "            selected_clients.append(i - 1)\n",
        "            j -= clients[i - 1]['Energy']\n",
        "        i -= 1\n",
        "\n",
        "    selected_client_features = [clients[idx] for idx in selected_clients]\n",
        "\n",
        "    return selected_clients, selected_client_features\n",
        "\n",
        "# Client features:\n",
        "clients = [\n",
        "    {\"Di\": 6000, \"Loss\": 0.3372, \"Delay\": 1.421, \"Energy\": 58, \"Reliability\": 0.1210938634, \"Fairness\": 0.66},\n",
        "    {\"Di\": 6000, \"Loss\": 0.6755, \"Delay\": 2, \"Energy\": 64, \"Reliability\": 0.04978706837, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.5286, \"Delay\": 2.16, \"Energy\": 47, \"Reliability\": 0.2493522088, \"Fairness\": 0.63},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4091, \"Delay\": 1.27, \"Energy\": 38, \"Reliability\": 1, \"Fairness\": 0.6},\n",
        "    {\"Di\": 6000, \"Loss\": 0.3258, \"Delay\": 1.17, \"Energy\": 42, \"Reliability\": 1, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4178, \"Delay\": 1.753, \"Energy\": 65, \"Reliability\": 0.1806214331, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.13236, \"Delay\": 1.8, \"Energy\": 36, \"Reliability\": 0.03567399335, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.2377, \"Delay\": 2.142, \"Energy\": 13, \"Reliability\": 1, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.323, \"Delay\": 2.52, \"Energy\": 16,\"Reliability\": 0.02811565975, \"Fairness\": 0.9333333333},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4094, \"Delay\": 1.8, \"Energy\": 96, \"Reliability\": 0.1888756028, \"Fairness\": 0.9333333333}\n",
        "]\n",
        "capacity = 200\n",
        "\n",
        "selected_clients, selected_client_features = knapsack_with_features(clients, capacity)\n",
        "print(\"Selected clients:\", selected_clients)\n",
        "print(\"Selected client features:\", selected_client_features)"
      ],
      "metadata": {
        "id": "Og5zCJ-CQXm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Create and compile the client model\n",
        "def create_client_model():\n",
        "    model = Model.build(input_shape=(28, 28, 1), classes=NUMOFCLASSES, final_activation='softmax', drop_rate=DROP_RATE)\n",
        "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Select clients based on knapsack scores\n",
        "def select_clients(knapsack_scores, num_clients):\n",
        "\n",
        "    selected_clients = np.argsort(knapsack_scores)[-num_clients:]\n",
        "    return selected_clients\n",
        "\n",
        "# Perform federated learning with client selection\n",
        "def federated_learning_with_selection(clients, capacity, num_clients, num_epochs, client_epochs, batch_size):\n",
        "    # Load dataset\n",
        "    (X_train, Y_train), (X_test, Y_test) = load_dataset()\n",
        "\n",
        "    # Initialize global model\n",
        "    global_model = create_client_model()\n",
        "\n",
        "    # Initialize knapsack scores for each client\n",
        "    knapsack_scores = [random.uniform(0, 1) for _ in range(len(clients))]\n",
        "\n",
        "    # Federated learning loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nGlobal Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        start_global_time = time.time()\n",
        "\n",
        "        # Select clients using knapsack algorithm\n",
        "        selected_clients_indices, _ = knapsack_with_features(clients, capacity)\n",
        "        selected_clients = [clients[i] for i in selected_clients_indices]\n",
        "\n",
        "        for client in selected_clients:\n",
        "            print(f\"\\nClient {clients.index(client) + 1}/{len(clients)}\")\n",
        "            # Create a local model\n",
        "            local_model = create_client_model()\n",
        "\n",
        "            # Train the local model\n",
        "            start_local_time = time.time()\n",
        "            local_model.fit(X_train, Y_train, epochs=client_epochs, batch_size=batch_size, verbose=0)\n",
        "            end_local_time = time.time()\n",
        "\n",
        "            # Evaluate local model on client's data\n",
        "            _, local_accuracy = local_model.evaluate(X_test, Y_test, verbose=0)\n",
        "            local_loss = 1 - local_accuracy\n",
        "\n",
        "            # Update knapsack score for the client\n",
        "            knapsack_scores[clients.index(client)] = local_loss\n",
        "\n",
        "            # Print results for each iteration\n",
        "            print(f\"Iteration {client_epochs}, Time: {end_local_time - start_local_time:.2f}s, Accuracy: {local_accuracy * 100:.2f}%, Loss: {local_loss:.4f}\")\n",
        "\n",
        "            # Aggregate models from selected clients into the global model (in this example, simply update the global model)\n",
        "            global_model.set_weights(local_model.get_weights())\n",
        "\n",
        "        end_global_time = time.time()\n",
        "        global_accuracy = global_model.evaluate(X_test, Y_test)[1]\n",
        "        global_loss = 1 - global_accuracy\n",
        "        print(f\"\\nGlobal Epoch Time: {end_global_time - start_global_time:.2f}s, Global Accuracy: {global_accuracy * 100:.2f}%, Global Loss: {global_loss:.4f}\")\n",
        "\n",
        "    # Evaluate the final global model\n",
        "    _, final_accuracy = global_model.evaluate(X_test, Y_test)\n",
        "    print(f\"\\nFinal Global Model Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Example:\n",
        "clients = [\n",
        "    {\"Di\": 6000, \"Loss\": 0.3372, \"Delay\": 1.421, \"Energy\": 58, \"Reliability\": 0.1210938634, \"Fairness\": 0.66},\n",
        "    {\"Di\": 6000, \"Loss\": 0.6755, \"Delay\": 2, \"Energy\": 64, \"Reliability\": 0.04978706837, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.5286, \"Delay\": 2.16, \"Energy\": 47, \"Reliability\": 0.2493522088, \"Fairness\": 0.63},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4091, \"Delay\": 1.27, \"Energy\": 38, \"Reliability\": 1, \"Fairness\": 0.6},\n",
        "    {\"Di\": 6000, \"Loss\": 0.3258, \"Delay\": 1.17, \"Energy\": 42, \"Reliability\": 1, \"Fairness\": 0.83},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4178, \"Delay\": 1.753, \"Energy\": 65, \"Reliability\": 0.1806214331, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.13236, \"Delay\": 1.8, \"Energy\": 36, \"Reliability\": 0.03567399335, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.2377, \"Delay\": 2.142, \"Energy\": 13, \"Reliability\": 1, \"Fairness\": 1},\n",
        "    {\"Di\": 6000, \"Loss\": 0.323, \"Delay\": 2.52, \"Energy\": 16,\"Reliability\": 0.02811565975, \"Fairness\": 0.9333333333},\n",
        "    {\"Di\": 6000, \"Loss\": 0.4094, \"Delay\": 1.8, \"Energy\": 96, \"Reliability\": 0.1888756028, \"Fairness\": 0.9333333333}\n",
        "]\n",
        "capacity = 200\n",
        "NUMOFCLASSES = 10\n",
        "LOSS = 'categorical_crossentropy'\n",
        "OPTIMIZER = 'adam'\n",
        "DROP_RATE = 0.25\n",
        "EPOCHS = 30\n",
        "CLIENT_EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "federated_learning_with_selection(clients, capacity, NUMOFCLIENTS, EPOCHS, CLIENT_EPOCHS, BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "uZRI9czOctYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}